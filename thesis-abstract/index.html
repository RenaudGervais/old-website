<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Getting Out of Flatland: Interaction and Introspection with Tangible Augmented Objects &#8211; Renaud Gervais</title>

<meta name="keywords" content="">



<!-- Twitter Cards -->
<meta name="twitter:title" content="Getting Out of Flatland: Interaction and Introspection with Tangible Augmented Objects">

<meta name="twitter:site" content="@RenaudGervais">
<meta name="twitter:creator" content="@RenaudGervais">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://renaudgervais.github.io/images/CCoO_header.jpg">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Getting Out of Flatland: Interaction and Introspection with Tangible Augmented Objects">

<meta property="og:url" content="http://renaudgervais.github.io/thesis-abstract/">
<meta property="og:site_name" content="Renaud Gervais">

<meta property="og:image" content="http://renaudgervais.github.io/images/CCoO_header.jpg">






<link rel="canonical" href="http://renaudgervais.github.io/thesis-abstract/">
<link href="http://renaudgervais.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Renaud Gervais Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://renaudgervais.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://renaudgervais.github.io/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://renaudgervais.github.io/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://renaudgervais.github.io/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://renaudgervais.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://renaudgervais.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://renaudgervais.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://renaudgervais.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://renaudgervais.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://renaudgervais.github.io/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="page">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://renaudgervais.github.io/">Renaud Gervais</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				        
				    
				    <li><a href="http://renaudgervais.github.io/" >Home</a></li>
				
				    
				        
				    
				    <li><a href="http://renaudgervais.github.io/projects/" >Projects</a></li>
				
				    
				        
				    
				    <li><a href="http://renaudgervais.github.io/publications/" >Publications</a></li>
				
				    
				        
				    
				    <li><a href="http://renaudgervais.github.io/about/" >About</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->


  
  <div class="image-wrap">
  <img src=
    
      "http://renaudgervais.github.io/images/CCoO_header.jpg"
    
  alt="Getting Out of Flatland: Interaction and Introspection with Tangible Augmented Objects feature image">
    <!-- img -->
  <!-- /.v4p -->


<div id="main" role="main">
  <div class="article-author-side">
    


<div itemscope itemtype="http://schema.org/Person">


	<img src="http://renaudgervais.github.io/images/bio-photo-2.jpg" class="bio-photo" alt="Renaud Gervais bio photo">


  <h3 itemprop="name">Renaud Gervais</h3>
  <p>Researcher, designer, programmer. I like tinkering with ideas that lie at the boundaries of different fields.</p>
  <a href="mailto:renaud.gervais@gmail.com" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a>
  <a href="http://twitter.com/RenaudGervais" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a>
  
  <a href="http://plus.google.com/+RenaudGervais-1" class="author-social" target="_blank"><i class="fa fa-fw fa-google-plus-square"></i> Google+</a>
  <a href="http://linkedin.com/in/renaud-gervais/27/7b6/338" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a>
  
  
  
  <a href="http://github.com/RenaudGervais" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  <a href="http://lastfm.com/user/NonRealResult" class="author-social" target="_blank"><i class="fa fa-fw fa-music"></i> Last.fm</a>
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="page">
    <h1>Getting Out of Flatland: Interaction and Introspection with Tangible Augmented Objects</h1>
    <div class="article-wrap">
      <!-- ### Motivation: Why do we care about the problem and the results? -->
<p>Most of our waking hours are now spent staring at a screen. While the advances in touch screens have enabled a more expressive interaction space with our devices, by using our fingers to interact with digital content, what we see and manipulate on screen is still being kept away from us, locked behind a glassy surface. The range of capabilities of the human senses is much richer than what screens can currently offer. In order to be sustainable in the future, interaction with the digital world should leverage these human capabilities instead of letting them atrophy. One way to provide richer interaction and visualization modalities is to rely on the physical world itself as a host for digital content. Spatial Augmented Reality provides a technical mean towards this idea, by using projectors to shed digitally controlled light onto real-world objects to augment them and their environment with features and content. This paves the way to a future where everyday objects will be embedded with rich and expressive capabilities, while still being anchored in the real world.</p>

<!-- ### Problem statement: What problem are your trying to solve? -->
<p>In this thesis, we are interested in two main aspects related to these tangible augmented objects. In a first time, we are raising the question on how to interact with digital content when it is hosted on physical objects. As a basis for our investigation, we studied interaction modalities that leverage traditional input and output devices found in a typical desktop environment. Our rationale for this approach is to leverage the experience of users with traditional digital tools – tools which researchers and developers spent decades to make simpler and more efficient to use – while at the same time steering towards a physically enriched interaction space. In a second time, we go beyond the interaction with the digital content of augmented objects and reflect on their potential as a humane medium support. We investigate how these augmented artifacts, combined with physiological computing, can be used to raise our awareness of the processes of our own bodies and minds and, eventually, foster introspection activities. This took the form of two different projects where we used tangible avatars to let users explore and customize real-time physiological feedback of their own inner states.</p>

<h2 id="interaction-with-spatial-augmented-reality">Interaction with Spatial Augmented Reality</h2>
<p>The first part of the thesis is focusing on the interaction with physical objects, augmented using SAR. The work includes an evaluation of a pointing technique (CurSAR) and an interaction metaphor for bridging interaction on traditional computer screens and physical augmented objects.</p>

<h3 id="cursar">CurSAR</h3>
<p><a href="/images/abstract-cursar.jpg"><img src="/images/cursar-header.jpg" alt="" /></a></p>

<p><a href="http://renaudgervais.github.io/cursar-pointing-in-spatial-augmented-reality-from-2d-pointing-devices/"><strong>CurSAR</strong></a> is a project investigating the use of 2D input devices to point at augmented physical objects. The main goal of the study was to compare the performance of a pointing task in a SAR and SCREEN condition. We created an experimental setup that allowed to have the same view of augmented objects either physical (SAR) or virtual (SCREEN).  Participants were 11% slower in the SAR condition. However, the transfer function of the mouse to the cursor, even without the physical presence of a screen as a reference system for the cursor, continued to the be effective.</p>

<h3 id="tangible-viewports-bridging-desktop-computers-and-physical-augmented-objects">Tangible Viewports: Bridging Desktop Computers and Physical Augmented Objects</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/q1lcti0P8Rk" frameborder="0" allowfullscreen=""></iframe>

<p>Tangible Viewports is an interaction metaphor developed to integrate physical objects into a desktop computer environment. It consists of an on-screen window that is aware of physical objects placed in front of it. When the screen cursor is about to be occluded by the object from the point of view of the user, the cursor appears on the surface of the physical object. Most activities involving digital creation are still conveyed on desktop or laptop computers (e.g. design, graphics, programming, etc). Enabling seamless interaction between native computer applications such as Photoshop and programming environments and physical objects makes it possible to envision a way to let users and developers create, tweak and interact with augmented objects with traditional tools.</p>

<p>The proposed system also supports different input modalities depending of the object’s spatial relationship with the screen. When located in front of the screen, it is possible to use any computer input device (i.e. mouse, graphics tablet) to create graphics, animations and interactive elements on the surface of the object directly. When the object is picked up, it is for example possible to interact with the different elements with direct touch. Considered in a creative workflow, this quick back and forth between the development environment (screen-centric) and the direct manipulation (handheld) could reduce the feedback loop when iterating over an idea or design.</p>

<h2 id="physiological-introspection-with-tangible-augmented-objects">Physiological Introspection with Tangible Augmented Objects</h2>
<p>The body is the most intimate thing we have. Even though we live with it everyday of our life, many of the internal intricacies of our inner states are not explicitly made available to us. In this chapter, we are interested in the use of tangible augmented objects as a way to expose and explore our inner states in a playful way.</p>

<h3 id="teegi-tangible-eeg-interface">Teegi: Tangible EEG Interface</h3>
<iframe src="//player.vimeo.com/video/104486980" width="500" height="281" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>

<p><a href="http://renaudgervais.github.io/teegi-tangible-eeg-interface/"><strong>Teegi</strong></a> is a Tangible EEG (ElectroEncephaloGraphy) Interface. It uses a physical puppet on which your brain activity is displayed in real-time using SAR. EEG technologies are still very complex and the knowledge required to have access to EEG readings and processing can be a deterrent for novice users that are interested in the brain. By creating a fully tangible installation, users can explore their own brain activity by manipulating dedicated mini-puppets that each corresponds to a high level brain activity (closing eyes, motor movement, relaxation/meditation). Users are free to explore what happens in their EEG readings by moving their limbs or try to changer their inner state and locate the brain regions that are specific to these activities.</p>

<h3 id="tobe-tangible-out-of-body-experience">TOBE: Tangible Out of Body Experience</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/yX0rMKO1aVA" frameborder="0" allowfullscreen=""></iframe>

<p>TOBE stands for Tangible Out of Body Experience. It is a direct follow-up of the Teegi project that is interested in increasing the freedom of the users regarding two factors: the physiological readings and the visual representations of said readings. The main idea of this platform is to allow users to build a tangible augmented avatar that will react to their own body’s internal state. Compared to Teegi, users have access to a greater range of physiological sensors such as ECG, breathing, GSR and some interpreted EEG signals. Moreover, they are creating the visual mapping themselves by selecting a visual representation, creating an animation using a simplified touch interface and linking it to one of their real-time physiological readings.</p>

<p>By letting users create their own representations of their real-time inner state through a tangible avatar, we are interested to see if users are more involved with their own physiology. Additionally, it can serve as a mediation facilitator, letting novice users explore what can be measured on the body, the way it is measured and how they relate to these measurements.</p>

<h2 id="publications">Publications</h2>

<ol class="bibliography"><li><span id="Gervais2016">Gervais, Renaud, Joan Sol Roo, and Martin Hachet. “Tangible Viewports: Getting Out Of Flatland in Desktop Environments.” In <i>Proceedings Of the 10th International Conference on Tangible, Embedded and Embodied Interaction</i>. TEI ’16. Eindhoven, Netherlands: ACM, 2016. https://hal.archives-ouvertes.fr/hal-01215502.</span>

</li>
<li><span id="Gervais2016a">Gervais, Renaud, Jérémy Frey, Alexis Gay, Fabien Lotte, and Martin Hachet. “TOBE: Tangible Out-Of-Body Experience.” In <i>Proceedings Of the 10th International Conference on Tangible, Embedded and Embodied Interaction</i>. TEI ’16. Eindhoven, Netherlands: ACM, 2016. https://hal.archives-ouvertes.fr/hal-01215499.</span>

</li>
<li><span id="Gervais2015">Gervais, Renaud, Jérémy Frey, and Martin Hachet. “Pointing In Spatial Augmented Reality from 2D Pointing Devices.” In <i>INTERACT</i>, 8. Bamberg, Germany, 2015. https://hal.archives-ouvertes.fr/hal-01153647.</span>


<a href="/./papers/Gervais2015.pdf"><img src="/images/pdf.png" style="width: 16px; height: 16px;" /></a>
</li>
<li><span id="Gervais2014">Gervais, Renaud, Jérémy Laviole, and Asier Marzo. “The Good, The Bad and the Hacked: Creative Coding on Objects.” In <i>Proceedings Of the 8th International Conference on Tangible, Embedded and Embodied Interaction WiP Poster</i>. TEI ’14. ACM, 2014.</span>


<a href="/./papers/Gervais2014.pdf"><img src="/images/pdf.png" style="width: 16px; height: 16px;" /></a>
</li>
<li><span id="Frey2014">Frey, Jérémy, Renaud Gervais, Stéphanie Fleck, Fabien Lotte, and Martin Hachet. “Teegi: Tangible EEG Interface.” In <i>Proceedings Of the 27th Annual ACM Symposium on User Interface Software and Technology</i>. UIST ’14. ACM, 2014.</span>


<a href="/./papers/Frey2014.pdf"><img src="/images/pdf.png" style="width: 16px; height: 16px;" /></a>
</li></ol>

      
        <hr />
        <div class="social-share">
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://renaudgervais.github.io/thesis-abstract/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://renaudgervais.github.io/thesis-abstract/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://renaudgervais.github.io/thesis-abstract/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>
</div><!-- /.social-share -->
      
    </div><!-- /.article-wrap -->
    
  </article>
</div><!-- /#index -->

<div class="footer-wrap">
  <footer>
    

<span>&copy; 2015 Renaud Gervais. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://renaudgervais.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://renaudgervais.github.io/assets/js/scripts.min.js"></script>



<!-- vvvv.js initialization -->


</body>
</html>
